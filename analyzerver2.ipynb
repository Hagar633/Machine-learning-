{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2YhJHeDvrP3BAMooZZbuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hagar633/Machine-learning-/blob/main/analyzerver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y mediapipe\n",
        "!pip install mediapipe==0.10.11\n",
        "!pip install decord\n",
        "\n",
        "!pip install git+https://github.com/apple/ml-depth-pro.git\n",
        "!mkdir -p checkpoints\n",
        "!wget https://huggingface.co/apple/DepthPro/resolve/main/depth_pro.pt -O checkpoints/depth_pro.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbcnzLomobVE",
        "outputId": "99914678-e9d0-4015-cc2e-d0fea7c234a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-18 19:36:43--  https://huggingface.co/apple/DepthPro/resolve/main/depth_pro.pt\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.97, 13.35.202.40, 13.35.202.34, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/c3/f3/c3f3eea459224d17357ca9be878608d1562e5fdd7e5dfaab42edb3dd15a6133a/3eb35ca68168ad3d14cb150f8947a4edf85589941661fdb2686259c80685c0ce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27depth_pro.pt%3B+filename%3D%22depth_pro.pt%22%3B&Expires=1755549404&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NTU0OTQwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2YzL2MzZjNlZWE0NTkyMjRkMTczNTdjYTliZTg3ODYwOGQxNTYyZTVmZGQ3ZTVkZmFhYjQyZWRiM2RkMTVhNjEzM2EvM2ViMzVjYTY4MTY4YWQzZDE0Y2IxNTBmODk0N2E0ZWRmODU1ODk5NDE2NjFmZGIyNjg2MjU5YzgwNjg1YzBjZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=p6AeK17hmOvIqum3nHYXTcbj%7E12zqDV4s3UsL35AwIfGv0IfIAwgXOLOwlDHEpgw3imT4RsngA1opyzkuDTKrFoED-VAoz7xE-h5W-k0A6MgsvYICAKQcDAfY9S0dSIEdcICit-8JAI37B6Vu26XvJheJW855x%7E9hNBAcgE-ujN78zpoPgeqo148pb2QG5jG5-VrGok2iR%7E%7EB7IAyXNSrlfzrggjuRK46nQZeFF6zLLmAM86fgVBOZUJhWG3bfx1YYRZc8JmZF5M2nSKkx3TAGBSuCiH3tqX3QgY4r17uPd0AoCLEML64WbyGAk5%7EechXlpGWvP1UiZjCoTHiQ3tDA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-08-18 19:36:44--  https://cdn-lfs-us-1.hf.co/repos/c3/f3/c3f3eea459224d17357ca9be878608d1562e5fdd7e5dfaab42edb3dd15a6133a/3eb35ca68168ad3d14cb150f8947a4edf85589941661fdb2686259c80685c0ce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27depth_pro.pt%3B+filename%3D%22depth_pro.pt%22%3B&Expires=1755549404&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NTU0OTQwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2MzL2YzL2MzZjNlZWE0NTkyMjRkMTczNTdjYTliZTg3ODYwOGQxNTYyZTVmZGQ3ZTVkZmFhYjQyZWRiM2RkMTVhNjEzM2EvM2ViMzVjYTY4MTY4YWQzZDE0Y2IxNTBmODk0N2E0ZWRmODU1ODk5NDE2NjFmZGIyNjg2MjU5YzgwNjg1YzBjZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=p6AeK17hmOvIqum3nHYXTcbj%7E12zqDV4s3UsL35AwIfGv0IfIAwgXOLOwlDHEpgw3imT4RsngA1opyzkuDTKrFoED-VAoz7xE-h5W-k0A6MgsvYICAKQcDAfY9S0dSIEdcICit-8JAI37B6Vu26XvJheJW855x%7E9hNBAcgE-ujN78zpoPgeqo148pb2QG5jG5-VrGok2iR%7E%7EB7IAyXNSrlfzrggjuRK46nQZeFF6zLLmAM86fgVBOZUJhWG3bfx1YYRZc8JmZF5M2nSKkx3TAGBSuCiH3tqX3QgY4r17uPd0AoCLEML64WbyGAk5%7EechXlpGWvP1UiZjCoTHiQ3tDA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 108.156.144.19, 108.156.144.84, 108.156.144.118, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.156.144.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1904446787 (1.8G) [binary/octet-stream]\n",
            "Saving to: ‘checkpoints/depth_pro.pt’\n",
            "\n",
            "checkpoints/depth_p 100%[===================>]   1.77G  80.5MB/s    in 11s     \n",
            "\n",
            "2025-08-18 19:36:54 (169 MB/s) - ‘checkpoints/depth_pro.pt’ saved [1904446787/1904446787]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsgmJB6-xvdy",
        "outputId": "4ca91398-dfca-47db-b2a1-a8900a86e181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames: 223\n",
            "stability is 0.004023175328563197\n",
            "stability is 0.2959222384142898\n",
            "stability is 0.1961956863511506\n",
            "stability is 0.39001124022224226\n",
            "stability is 0.016216424213932087\n",
            "stability is 0.4859964939243074\n",
            "stability is 0.04131629679353538\n",
            "stability is 0.6460986504176067\n",
            "stability is 0.008657456654357997\n",
            "stability is 0.6571123300397034\n",
            "stability is 0.007500819250633762\n",
            "stability is 1.5386070132881038\n",
            "stability is 0.01665739464720938\n",
            "stability is 0.21284124247780078\n",
            "stability is 0.2187201242159825\n",
            "stability is 0.3254788847007349\n",
            "stability is 0.17471208863015758\n",
            "stability is 0.19856884974326425\n",
            "stability is 0.1990204406243529\n",
            "stability is 0.22635766797849002\n",
            "stability is 0.34788215163261904\n",
            "stability is 0.023908314086395325\n",
            "stability is 0.7566928033619718\n",
            "stability is 0.021261387541210788\n",
            "stability is 0.14786960029764395\n",
            "stability is 0.07697401906543214\n",
            "stability is 0.07244677954298295\n",
            "stability is 0.6306775167067011\n",
            "stability is 0.008173685225111336\n",
            "stability is 0.6776878807890433\n",
            "stability is 0.2723845845502959\n",
            "stability is 0.10753687675591504\n",
            "Video saved to kid1_fin.mp4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import depth_pro\n",
        "model, transform = depth_pro.create_model_and_transforms()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device).eval()\n",
        "model = model.half().to(device).eval()\n",
        "from pickle import FRAME\n",
        "from google.colab.patches import cv2_imshow\n",
        "from decord import VideoReader\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import statistics\n",
        "\n",
        "video_path = \"kid1.mp4\"\n",
        "vr = VideoReader(video_path)\n",
        "frame_count = len(vr)\n",
        "print(f\"Total frames: {frame_count}\")\n",
        "output_path = \"kid1_fin.mp4\"\n",
        "\n",
        "def approximate_intrinsics(width, height):\n",
        "    c_x, c_y = width/2, height/2\n",
        "    return float(c_x), float(c_y)\n",
        "\n",
        "\n",
        "def pixel_to_camera_coords(x, y, Z, f_x, f_y, c_x, c_y):\n",
        "   X = (x - c_x) * Z / f_x\n",
        "   Y = (y - c_y) * Z / f_y\n",
        "   return X, Y, Z\n",
        "\n",
        "def stability_calc(frame, depth_map, fx,fy, results, c_x, c_y):\n",
        "  points = {}\n",
        "  mp_pose = mp.solutions.pose\n",
        "\n",
        "  h, w, _ = frame.shape\n",
        "  for id, lm in enumerate(results.pose_landmarks.landmark):\n",
        "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "\n",
        "        cz = depth_map[cy, cx]\n",
        "        X, Y, Z = pixel_to_camera_coords(cx, cy, cz, fx, fy, c_x, c_y)\n",
        "        if id == mp_pose.PoseLandmark.LEFT_ANKLE.value:\n",
        "            points[\"left_ankle\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.RIGHT_ANKLE.value:\n",
        "            points[\"right_ankle\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.LEFT_HIP.value:\n",
        "            points[\"left_hip\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.RIGHT_HIP.value:\n",
        "            points[\"right_hip\"] = (X, Y, Z)\n",
        "\n",
        "        if id in [mp_pose.PoseLandmark.LEFT_ANKLE.value,\n",
        "                  mp_pose.PoseLandmark.RIGHT_ANKLE.value]:\n",
        "            cv2.circle(frame, (cx, cy), 5, (0, 255, 0), cv2.FILLED)\n",
        "\n",
        "  mp_draw.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "\n",
        "  com_x = (points[\"left_hip\"][0] + points[\"right_hip\"][0]) / 2\n",
        "  com_y = (points[\"left_hip\"][1] + points[\"right_hip\"][1]) / 2\n",
        "  com_z = (points[\"left_hip\"][2] + points[\"right_hip\"][2]) / 2\n",
        "\n",
        "  foot_midx = (points[\"left_ankle\"][0] + points[\"right_ankle\"][0]) / 2\n",
        "  foot_midy = (points[\"left_ankle\"][1] + points[\"right_ankle\"][1]) / 2\n",
        "  foot_midz = (points[\"left_ankle\"][2] + points[\"right_ankle\"][2]) / 2\n",
        "\n",
        "  stance_width= abs(points[\"left_ankle\"][0] -  points[\"right_ankle\"][0])\n",
        "  sway = abs(com_x - foot_midx)\n",
        "  norm= sway/stance_width\n",
        "  return norm\n",
        "\n",
        "# Sample every 5 seconds (assuming 30 fps)\n",
        "fps = 7\n",
        "step = fps * 1\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=True)\n",
        "mp_draw = mp.solutions.drawing_utils\n",
        "\n",
        "sample_frame = vr[0].asnumpy()\n",
        "height, width, _ = sample_frame.shape\n",
        "c_x,c_y= approximate_intrinsics(width, height)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "var = 0\n",
        "norms = []\n",
        "for i in range(0, frame_count, step):\n",
        "\n",
        "    frame = vr[i].asnumpy()\n",
        "    rgb = cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
        "    results = pose.process(rgb)\n",
        "    img = transform(rgb).unsqueeze(0).to(device).half()\n",
        "    with torch.no_grad():\n",
        "        pred = model.infer(img)\n",
        "        depth_map = pred[\"depth\"].squeeze().cpu().numpy()\n",
        "        depth_map = cv2.resize(depth_map, (frame.shape[1], frame.shape[0]))\n",
        "        intrinsics = pred[\"focallength_px\"].cpu().numpy()\n",
        "        if np.ndim(intrinsics) == 0:\n",
        "          fx = fy = float(intrinsics)\n",
        "        else:\n",
        "          fx, fy = intrinsics\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "      norm= stability_calc(frame, depth_map, fx,fy, results,c_x,c_y)\n",
        "      norms.append(norm)\n",
        "    if len(norms) > 1:\n",
        "      var = statistics.variance(norms)\n",
        "    print(\"stability is\" , norm)\n",
        "    cv2.putText(frame,\n",
        "            f\"Frame: {i} | Stability: {norm:.2f} | Variance: {var:.2f}\",\n",
        "            (10, 20),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.5,\n",
        "            (0, 0, 200),\n",
        "            2,\n",
        "            cv2.LINE_AA)\n",
        "    out.write(frame)\n",
        "\n",
        "\n",
        "# --- ADD 3-SECOND BLACK FRAME WITH FINAL TEXT ---\n",
        "black_frame = np.zeros_like(frame)  # same size as video frames\n",
        "avg_stability = np.mean(norms)\n",
        "final_var = statistics.variance(norms) if len(norms) > 1 else 0\n",
        "\n",
        "# write fps * 3 frames (3 seconds)\n",
        "for _ in range(fps * 3):\n",
        "    # make a copy so we don't overwrite black_frame itself\n",
        "    frame_with_text = black_frame.copy()\n",
        "\n",
        "    txt = f\"Average Stability: {avg_stability:.2f} | Final Variance: {final_var:.2f}\"\n",
        "    cv2.putText(frame_with_text,\n",
        "                txt,\n",
        "                (5, height // 2),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.5,\n",
        "                (255, 255, 255),\n",
        "                2,\n",
        "                cv2.LINE_AA)\n",
        "\n",
        "    out.write(frame_with_text)\n",
        "\n",
        "out.release()\n",
        "print(f\"Video saved to {output_path}\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}