{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsKJpFIBreC1DR+XQokbp7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hagar633/Machine-learning-/blob/main/depthmodel_coordinates_update_kidplaying.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsgmJB6-xvdy",
        "outputId": "b76416d0-7a49-4ff3-b6eb-b7611daf2045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames: 223\n",
            "stability is 0.004023175328563192\n",
            "stability is 0.29592223841428983\n",
            "stability is 0.19619568635115053\n",
            "stability is 0.3900112402222423\n",
            "stability is 0.0162164242139321\n",
            "stability is 0.48599649392430744\n",
            "stability is 0.04131629679353541\n",
            "stability is 0.6460986504176065\n",
            "stability is 0.008657456654358004\n",
            "stability is 0.6571123300397036\n",
            "stability is 0.007500819250633769\n",
            "stability is 1.5386070132881042\n",
            "stability is 0.01665739464720946\n",
            "stability is 0.2128412424778008\n",
            "stability is 0.2187201242159825\n",
            "stability is 0.32547888470073494\n",
            "stability is 0.17471208863015764\n",
            "stability is 0.1985688497432642\n",
            "stability is 0.1990204406243528\n",
            "stability is 0.22635766797849008\n",
            "stability is 0.347882151632619\n",
            "stability is 0.023908314086395325\n",
            "stability is 0.756692803361972\n",
            "stability is 0.02126138754121081\n",
            "stability is 0.14786960029764415\n",
            "stability is 0.07697401906543215\n",
            "stability is 0.07244677954298295\n",
            "stability is 0.6306775167067011\n",
            "stability is 0.008173685225111357\n",
            "stability is 0.6776878807890432\n",
            "stability is 0.2723845845502959\n",
            "stability is 0.10753687675591503\n",
            "Video saved to kid1_fin.mp4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import depth_pro\n",
        "model, transform = depth_pro.create_model_and_transforms()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device).eval()\n",
        "model = model.half().to(device).eval()\n",
        "from pickle import FRAME\n",
        "from google.colab.patches import cv2_imshow\n",
        "from decord import VideoReader\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import statistics\n",
        "\n",
        "video_path = \"kid1.mp4\"\n",
        "vr = VideoReader(video_path)\n",
        "frame_count = len(vr)\n",
        "print(f\"Total frames: {frame_count}\")\n",
        "output_path = \"kid1_fin.mp4\"\n",
        "\n",
        "def approximate_intrinsics(width, height, fov_x_deg=70):\n",
        "\n",
        "    fov_x = np.deg2rad(fov_x_deg)\n",
        "\n",
        "    fov_y = 2 * np.arctan((height/width) * np.tan(fov_x/2))\n",
        "\n",
        "    f_x = width  / (2 * np.tan(fov_x/2))\n",
        "    f_y = height / (2 * np.tan(fov_y/2))\n",
        "\n",
        "    c_x, c_y = width/2, height/2\n",
        "    return float(f_x), float(f_y), float(c_x), float(c_y)\n",
        "\n",
        "\n",
        "def pixel_to_camera_coords(x, y, Z, f_x, f_y, c_x, c_y):\n",
        "    \"\"\"Convert pixel (x,y) + depth Z â†’ camera 3D coordinates.\"\"\"\n",
        "    X = (x - c_x) * Z / f_x\n",
        "    Y = (y - c_y) * Z / f_y\n",
        "    return X, Y, Z\n",
        "\n",
        "\n",
        "# Sample every 5 seconds (assuming 30 fps)\n",
        "fps = 7\n",
        "step = fps * 1\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=True)\n",
        "mp_draw = mp.solutions.drawing_utils\n",
        "\n",
        "sample_frame = vr[0].asnumpy()\n",
        "height, width, _ = sample_frame.shape\n",
        "f_x, f_y, c_x, c_y = approximate_intrinsics(width, height, fov_x_deg=70)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "var = 0\n",
        "norms = []\n",
        "for i in range(0, frame_count, step):\n",
        "\n",
        "    frame = vr[i].asnumpy()\n",
        "    rgb = cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
        "    results = pose.process(rgb)\n",
        "    img = transform(rgb).unsqueeze(0).to(device).half()\n",
        "    with torch.no_grad():\n",
        "        pred = model.infer(img)\n",
        "        depth_map = pred[\"depth\"].squeeze().cpu().numpy()\n",
        "        depth_map = cv2.resize(depth_map, (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "    points = {}\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "      h, w, _ = frame.shape\n",
        "      for id, lm in enumerate(results.pose_landmarks.landmark):\n",
        "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "        cz = depth_map[cy, cx]\n",
        "        X, Y, Z = pixel_to_camera_coords(cx, cy, cz, f_x, f_y, c_x, c_y)\n",
        "        if id == mp_pose.PoseLandmark.LEFT_ANKLE.value:\n",
        "           points[\"left_ankle\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.RIGHT_ANKLE.value:\n",
        "            points[\"right_ankle\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.LEFT_HIP.value:\n",
        "            points[\"left_hip\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.RIGHT_HIP.value:\n",
        "            points[\"right_hip\"] = (X, Y, Z)\n",
        "        if id in [mp_pose.PoseLandmark.LEFT_ANKLE.value,\n",
        "                  mp_pose.PoseLandmark.RIGHT_ANKLE.value]:\n",
        "            cv2.circle(frame, (cx, cy), 5, (0, 255, 0), cv2.FILLED)\n",
        "\n",
        "    mp_draw.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "    torso_points = [p for k,p in points.items() if \"hip\" in k or \"shoulder\" in k]\n",
        "    if len(torso_points) >= 2:\n",
        "        com_x = np.mean([p[0] for p in torso_points])\n",
        "        com_y = np.mean([p[1] for p in torso_points])\n",
        "        com_z = np.mean([p[2] for p in torso_points])\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    foot_midx= (points[\"left_ankle\"][0]+  points[\"right_ankle\"][0])/2\n",
        "    foot_midy= (points[\"left_ankle\"][1]+  points[\"right_ankle\"][1])/2\n",
        "    foot_midz= (points[\"left_ankle\"][2]+  points[\"right_ankle\"][2])/2\n",
        "    stance_width= abs(points[\"left_ankle\"][0] -  points[\"right_ankle\"][0])\n",
        "    sway = abs(com_x - foot_midx)\n",
        "    norm= sway/stance_width\n",
        "    norms.append(norm)\n",
        "    if len(norms) > 1:\n",
        "      var = statistics.variance(norms)\n",
        "    print(\"stability is\" , norm)\n",
        "    cv2.putText(frame,\n",
        "            f\"Frame: {i} | Stability: {norm:.2f} | Variance: {var:.2f}\",\n",
        "            (10, 20),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.5,\n",
        "            (0, 0, 200),\n",
        "            2,\n",
        "            cv2.LINE_AA)\n",
        "    out.write(frame)\n",
        "out.release()\n",
        "print(f\"Video saved to {output_path}\")\n",
        "# cv2.circle(image, (int(com_x), int(com_y)),  5, (0, 255, 255), cv2.FILLED)\n",
        "# Show result in Colab\n",
        "\n"
      ]
    }
  ]
}