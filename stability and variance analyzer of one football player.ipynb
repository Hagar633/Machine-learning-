{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNcdpMtQfXVSLA33tRZ6qOH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hagar633/Machine-learning-/blob/main/stability%20and%20variance%20analyzer%20of%20one%20football%20player.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsgmJB6-xvdy",
        "outputId": "8b9b2628-9b96-4ed6-c326-1fa11726fd83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames: 223\n",
            "stability is 0.004023164\n",
            "stability is 0.29592225\n",
            "stability is 0.19619568\n",
            "stability is 0.39001125\n",
            "stability is 0.016216435\n",
            "stability is 0.48599654\n",
            "stability is 0.041316293\n",
            "stability is 0.64609855\n",
            "stability is 0.008657447\n",
            "stability is 0.65711224\n",
            "stability is 0.0075008287\n",
            "stability is 1.5386063\n",
            "stability is 0.016657379\n",
            "stability is 0.21284124\n",
            "stability is 0.2187201\n",
            "stability is 0.32547885\n",
            "stability is 0.17471206\n",
            "stability is 0.19856887\n",
            "stability is 0.19902043\n",
            "stability is 0.22635767\n",
            "stability is 0.34788218\n",
            "stability is 0.023908313\n",
            "stability is 0.75669277\n",
            "stability is 0.021261385\n",
            "stability is 0.1478696\n",
            "stability is 0.076974\n",
            "stability is 0.07244681\n",
            "stability is 0.63067746\n",
            "stability is 0.008173687\n",
            "stability is 0.67768776\n",
            "stability is 0.2723846\n",
            "stability is 0.10753688\n",
            "Video saved to kid1_fin.mp4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import depth_pro\n",
        "model, transform = depth_pro.create_model_and_transforms()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device).eval()\n",
        "model = model.half().to(device).eval()\n",
        "from pickle import FRAME\n",
        "from google.colab.patches import cv2_imshow\n",
        "from decord import VideoReader\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import statistics\n",
        "\n",
        "video_path = \"kid1.mp4\"\n",
        "vr = VideoReader(video_path)\n",
        "frame_count = len(vr)\n",
        "print(f\"Total frames: {frame_count}\")\n",
        "output_path = \"kid1_fin.mp4\"\n",
        "\n",
        "def approximate_intrinsics(width, height):\n",
        "    c_x, c_y = width/2, height/2\n",
        "    return float(c_x), float(c_y)\n",
        "\n",
        "\n",
        "def pixel_to_camera_coords(x, y, Z, f_x, f_y, c_x, c_y):\n",
        "   X = (x - c_x) * Z / f_x\n",
        "   Y = (y - c_y) * Z / f_y\n",
        "   return X, Y, Z\n",
        "\n",
        "def stability_calc(frame, depth_map, fx,fy, results, c_x, c_y):\n",
        "  points = {}\n",
        "  mp_pose = mp.solutions.pose\n",
        "\n",
        "  h, w, _ = frame.shape\n",
        "  for id, lm in enumerate(results.pose_landmarks.landmark):\n",
        "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "\n",
        "        cz = depth_map[cy, cx]\n",
        "        X, Y, Z = pixel_to_camera_coords(cx, cy, cz, fx, fy, c_x, c_y)\n",
        "        if id == mp_pose.PoseLandmark.LEFT_ANKLE.value:\n",
        "            points[\"left_ankle\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.RIGHT_ANKLE.value:\n",
        "            points[\"right_ankle\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.LEFT_HIP.value:\n",
        "            points[\"left_hip\"] = (X, Y, Z)\n",
        "        elif id == mp_pose.PoseLandmark.RIGHT_HIP.value:\n",
        "            points[\"right_hip\"] = (X, Y, Z)\n",
        "\n",
        "        if id in [mp_pose.PoseLandmark.LEFT_ANKLE.value,\n",
        "                  mp_pose.PoseLandmark.RIGHT_ANKLE.value]:\n",
        "            cv2.circle(frame, (cx, cy), 5, (0, 255, 0), cv2.FILLED)\n",
        "\n",
        "  mp_draw.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "\n",
        "  com_x = (points[\"left_hip\"][0] + points[\"right_hip\"][0]) / 2\n",
        "  com_y = (points[\"left_hip\"][1] + points[\"right_hip\"][1]) / 2\n",
        "  com_z = (points[\"left_hip\"][2] + points[\"right_hip\"][2]) / 2\n",
        "\n",
        "  foot_midx = (points[\"left_ankle\"][0] + points[\"right_ankle\"][0]) / 2\n",
        "  foot_midy = (points[\"left_ankle\"][1] + points[\"right_ankle\"][1]) / 2\n",
        "  foot_midz = (points[\"left_ankle\"][2] + points[\"right_ankle\"][2]) / 2\n",
        "\n",
        "  stance_width= abs(points[\"left_ankle\"][0] -  points[\"right_ankle\"][0])\n",
        "  sway = abs(com_x - foot_midx)\n",
        "  norm= sway/stance_width\n",
        "  return norm\n",
        "\n",
        "# Sample every 5 seconds (assuming 30 fps)\n",
        "fps = 7\n",
        "step = fps * 1\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=True)\n",
        "mp_draw = mp.solutions.drawing_utils\n",
        "\n",
        "sample_frame = vr[0].asnumpy()\n",
        "height, width, _ = sample_frame.shape\n",
        "c_x,c_y= approximate_intrinsics(width, height)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "var = 0\n",
        "norms = []\n",
        "for i in range(0, frame_count, step):\n",
        "\n",
        "    frame = vr[i].asnumpy()\n",
        "    rgb = cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
        "    results = pose.process(rgb)\n",
        "    img = transform(rgb).unsqueeze(0).to(device).half()\n",
        "    with torch.no_grad():\n",
        "        pred = model.infer(img)\n",
        "        depth_map = pred[\"depth\"].squeeze().cpu().numpy()\n",
        "        depth_map = cv2.resize(depth_map, (frame.shape[1], frame.shape[0]))\n",
        "        intrinsics = pred[\"focallength_px\"].cpu().numpy()\n",
        "        if np.ndim(intrinsics) == 0:\n",
        "          fx = fy = float(intrinsics)\n",
        "        else:\n",
        "          fx, fy = intrinsics\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "      norm= stability_calc(frame, depth_map, fx,fy, results,c_x,c_y)\n",
        "      norms.append(norm)\n",
        "    if len(norms) > 1:\n",
        "      var = statistics.variance(norms)\n",
        "    print(\"stability is\" , norm)\n",
        "    cv2.putText(frame,\n",
        "            f\"Frame: {i} | Stability: {norm:.2f} | Variance: {var:.2f}\",\n",
        "            (10, 20),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.5,\n",
        "            (0, 0, 200),\n",
        "            2,\n",
        "            cv2.LINE_AA)\n",
        "    out.write(frame)\n",
        "out.release()\n",
        "print(f\"Video saved to {output_path}\")\n",
        "\n"
      ]
    }
  ]
}